name: Daily Scrape (New Listings)

on:
  # Run daily at 6am UTC (early morning)
  schedule:
    - cron: '0 6 * * *'

  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape-new:
    name: Scrape New Listings (Pages 1-50)
    runs-on: ubuntu-latest
    timeout-minutes: 60
    environment: Production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraper/requirements.txt

      - name: Install dependencies
        run: pip install -r scraper/requirements.txt

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Run daily incremental scrape
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "ðŸ”„ Daily scrape: Pages 1-50 (newest listings)"
          python scraper/run.py \
            --start-page 1 \
            --end-page 50

      - name: Report completion
        if: always()
        run: |
          echo "=============================================="
          echo "âœ… Daily scrape completed"
          echo "   Pages: 1-50 (newest listings)"
          echo "   Status: ${{ job.status }}"
          echo "   Next full scrape: Sunday 3am UTC"
          echo "=============================================="
