name: Scrape Properties (Distributed)

on:
  # Run every Sunday at 3am UTC
  schedule:
    - cron: '0 3 * * 0'

  # Allow manual trigger from GitHub UI
  workflow_dispatch:
    inputs:
      job_count:
        description: 'Number of parallel jobs (default: 9)'
        required: false
        default: '9'
        type: choice
        options:
          - '1'
          - '3'
          - '5'
          - '9'
          - '12'

jobs:
  detect:
    name: Detect Total Pages
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      total_pages: ${{ steps.calculate.outputs.total }}
      page_ranges: ${{ steps.calculate.outputs.ranges }}
      job_count: ${{ steps.calculate.outputs.jobs }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install detection dependencies
        run: pip install playwright beautifulsoup4 lxml

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Detect page count and calculate ranges
        id: calculate
        run: |
          echo "ðŸ” Detecting total page count..."
          OUTPUT=$(python scraper/detect_pages.py)

          TOTAL=$(echo $OUTPUT | python3 -c "import sys, json; print(json.load(sys.stdin)['total_pages'])")
          RANGES=$(echo $OUTPUT | python3 -c "import sys, json; print(json.dumps(json.load(sys.stdin)['ranges']))")

          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "ranges=$RANGES" >> $GITHUB_OUTPUT
          echo "jobs=9" >> $GITHUB_OUTPUT

          echo "âœ… Detected $TOTAL total pages"
          echo "ðŸ“Š Split into 9 parallel jobs"

  scrape:
    name: ${{ matrix.page_range.name }} (Pages ${{ matrix.page_range.start }}-${{ matrix.page_range.end }})
    needs: detect
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours per job

    strategy:
      max-parallel: 10  # Run up to 10 jobs concurrently
      fail-fast: false  # Continue other jobs if one fails
      matrix:
        page_range: ${{ fromJson(needs.detect.outputs.page_ranges) }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraper/requirements.txt

      - name: Install dependencies
        run: pip install -r scraper/requirements.txt

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Run scraper for pages ${{ matrix.page_range.start }}-${{ matrix.page_range.end }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python scraper/run.py \
            --start-page ${{ matrix.page_range.start }} \
            --end-page ${{ matrix.page_range.end }}

      - name: Report completion
        if: always()
        run: |
          echo "=============================================="
          echo "âœ… Completed ${{ matrix.page_range.name }}"
          echo "   Pages: ${{ matrix.page_range.start }}-${{ matrix.page_range.end }}"
          echo "   Status: ${{ job.status }}"
          echo "   Time: $(date)"
          echo "=============================================="

  summary:
    name: Scrape Summary
    needs: [detect, scrape]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Check scrape results
        run: |
          echo "=============================================="
          echo "ðŸ“Š DISTRIBUTED SCRAPE SUMMARY"
          echo "=============================================="
          echo "Total pages detected: ${{ needs.detect.outputs.total_pages }}"
          echo "Jobs: ${{ needs.detect.outputs.job_count }} parallel"
          echo "Status: ${{ needs.scrape.result }}"
          echo ""
          echo "Next steps:"
          echo "- Check Supabase dashboard for listing count"
          echo "- Verify active listings count"
          echo "- Review any failed jobs above"
          echo "=============================================="
